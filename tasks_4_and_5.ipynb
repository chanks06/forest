{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71ce8af",
   "metadata": {},
   "source": [
    "# PREDICTING FOREST TYPE \n",
    "## Final Project, Python for Data Science \n",
    "### Willamette University MSDS \n",
    "by Charles Hanks, Carter McMahon, & Cleighton Roberts\n",
    "\n",
    "[Dataset](https://www.kaggle.com/datasets/uciml/forest-cover-type-dataset)\n",
    "\n",
    "# TASK 4 : IMPLEMENTATION & EVALUATION \n",
    "\n",
    "## Loading Libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc13209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febe89d",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5194e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('/Users/chanks/workspace/forest/data/covtype.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbafdbc3",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fbb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "\n",
    "ds.columns.get_loc('Cover_Type') # finding index of dependent variable \n",
    "\n",
    "numerical_features = ds.iloc[:,0:10]\n",
    "scaled_num_features =  pd.DataFrame(scale.fit_transform(numerical_features), columns = numerical_features.columns)\n",
    "\n",
    "ds = pd.concat([scaled_num_features, ds.iloc[:,10:]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d912cd",
   "metadata": {},
   "source": [
    "### Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd40b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting feature\n",
    "X = ds.drop(ds.columns[-1], axis = 1) #feature subset that excludes \"Cover Type\" target variable\n",
    "y = ds[ds.columns[-1]] #target variable \"Cover Type\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 650, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577e938",
   "metadata": {},
   "source": [
    "### Task 4.1 : Random Forest Classifier \n",
    "Implement a random forest classifier using sci-kit-learn. Create a subsection in your report describing the chosen parameters of the classifier and training method, and how they were set. Also, report the accuracy of the resulting method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32e975",
   "metadata": {},
   "source": [
    "### Task 4.2 : Support Vector Machine \n",
    " Modify your solution in Task 4.1 to use a Support Vector Machine (SVC) classifier using sci-kit- learn with the appropriate parameters including kernel = ‘linear’. Report the accuracy of the resulting method. Compare the results of the SVM model with the random forest model implemented in task 4.1. You may also justify the other parameters used or tuned in both models and how that affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75571a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2445201",
   "metadata": {},
   "source": [
    "The training attempt above takes an exceedingly long time. Per the [sci-kit learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html):\n",
    "\n",
    "*\"For large datasets consider using LinearSVC or SGDClassifier instead, possibly after a Nystroem transformer or other Kernel Approximation\"*\n",
    "\n",
    "Our dataset has 581,012 observations. We will proceed with the LinearSVC() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a116db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chanks/anaconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(random_state=650)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=650)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(random_state=650)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model_lsvc = LinearSVC(random_state = 650)\n",
    "model_lsvc.fit(X_train,y_train) #model took about 6 minutes to fit, that is much more efficient than SVC(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8cd8c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7115958325683863\n"
     ]
    }
   ],
   "source": [
    "#predicting forest type on test data using first linear SVC model:  \n",
    "lsvc_predict = model_lsvc.predict(X_test)\n",
    "\n",
    "#print accuracy score: \n",
    "print(accuracy_score(lsvc_predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2feb0",
   "metadata": {},
   "source": [
    "### SVC round 2: adding cross validation, a tune grid & PCA \n",
    "\n",
    "\n",
    "### Comparison of Random Forest vs. Support Vector Machine \n",
    "\n",
    "## Intro\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Random Forest\n",
    "The final random forest model that we chose only differed from the default hyperparameters in that the number of estimators was set to 250 rather than 100. We decided to do that after testing higher values for min_sample_leaf, min_sample_split, and n_estimators using GridSearchCV. The results of that cross-validated hyperparameter tuning grid showed that the default values for min_sample_leaf and min_sample_split were best in our case, and that 250 was better than 100 for n_estimators. Due to our limited access to computing power, 250 was the highest value that we tested for n_estimators, so it is possible that an even higher value could have yielded better accuracy scores.\n",
    "\n",
    "### Support Vector Machine\n",
    "\n",
    "\n",
    "### Clustering\n",
    "\n",
    "## Results\n",
    "\n",
    "### Random Forest\n",
    "Despite our hyperparameter tuning efforts, the resulting improvement in accuracy over default settings was minimal. The tuned model produced an accuracy score of 0.952521 compared to 0.95201 with the default hyperparameter settings.\n",
    "\n",
    "### Support Vector Machine\n",
    "\n",
    "\n",
    "### Clustering\n",
    "\n",
    "## Discussion and Implications\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "## References\n",
    "\n",
    "## Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
