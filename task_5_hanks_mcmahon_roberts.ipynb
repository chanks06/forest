{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5: Machine Learning Implementation & Evaluation \n",
    "## Predicting Forest Type \n",
    "\n",
    "### Final Project, Python for Data Science \n",
    "#### Willamette University MSDS \n",
    "by Charles Hanks, Carter McMahon, & Cleighton Roberts \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "The goal of our project was to predict the types of trees present in different areas of the Roosevelt National Forest in Colorado. We built a model using cartographic variables such as shadow coverage, distance to nearby landmarks, soil type, and local topography to classify tree type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The main problem we will address is how to identify the type of a tree based on its surroundings. If we know certain characteristics about a piece of land, such as elevation or the hillshade at noon, what sort of trees would we likely find there? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Research Question\n",
    "\n",
    "Which cartographic features are most predictive of tree type in the Roosevelt National Forest?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "### Random Forest\n",
    "The final random forest model that we chose only differed from the default hyperparameters in that the number of estimators was set to 250 rather than 100. We decided to do that after testing higher values for min_sample_leaf, min_sample_split, and n_estimators using GridSearchCV. The results of that cross-validated hyperparameter tuning grid showed that the default values for min_sample_leaf and min_sample_split were best in our case, and that 250 was better than 100 for n_estimators. Due to our limited access to computing power, 250 was the highest value that we tested for n_estimators, so it is possible that an even higher value could have yielded better accuracy scores.\n",
    "\n",
    "### Support Vector Machine \n",
    "Given the computational expensive of training a SVM model on a dataset of this size, we utilized the RandomSearchCV tuning grid method to optimize the model. We focused on 2 hyperparameters: 'C', the misclassification penalty, and 'max_iter', the number of times the algorithm iterates. We chose a logarithmic range of values to try for 'C', and for each value, a random 'max_iter' value between 1000 and 5000. Each combination of these hyperparameters was passed through 3-fold cross validation in our grid search. From this randomized grid search, the best value for 'C' was 14.37, and the best value for 'max_iter' was 1902. Unfortunately, we saw negligible increase in model performance with the random search best parameters. \n",
    "\n",
    "### K Nearest Neighbors \n",
    "We wanted to try a KNN model for two reasons. First, KNN is a more simple and fast algorithm compared to RF and SVM. Second, we suspected that it would perform well on geospatial data given that it is based on distance between data points. The best value for hyperparamter K was 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Random Forest \n",
    "Despite our hyperparameter tuning efforts, the resulting improvement in accuracy over default settings was minimal. The tuned model produced an accuracy score of 0.952521 compared to 0.95201 with the default hyperparameter settings.\n",
    "\n",
    "### Support Vector Machine \n",
    "Our best SVM model was the basesline LinearSVC Model trained on 70% of the dataset. The accuracy score of this model was .72. \n",
    "\n",
    "### K-Nearest Neighbors \n",
    "Our KNN model's performance was a pleasant surprise. With a k = 5, The accuracy score was .92. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion & Implications \n",
    "\n",
    "\n",
    "Based on our process of training and tuning the SVM models, we can say that this dataset is not suitable for a Support Vector Machine Model. During our exploratory data analysis, we found signficant overlap among classes. That is to say, many of the different tree types share similar characteristics - after all, they are in the same forest. SVMs do not perform well with very large dataset and when classes overlap (that data set has a lot of 'noise').  These two disadvantages explain why our SVM model did not accurately predict above a .71. \n",
    "\n",
    "KNN perform better than our expectations, given how relatively simple the algorithm is compared to RF and SVM. We suspect that KNN performed well due to much of our dataset was spatial distances, and KNN detects neighbors based on Euclidean distance in n-dimensional feature space. \n",
    "\n",
    "Random Forest is a tried and true model that produces consistently good results. We attribute this to the fact that our dataset contained many one-hot encoded (1/0) columns, so the model could quickly determine tree type by eliminating certain potential tree types. For example, there were tree types that were never found in certain soil types. An ensemble of decision trees excels with this sort of data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "Elevation is the cartographic feature most predictive of tree type. We arrived at this conclusion by examining the variable importance plot of our Random Forest model. Other important features include how far the tree is from a road, body of water, or where a fire has started. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our interpretation of our modeling is that human actions have a significant impact on the the types of trees that we find in the Roosevelt National Forest. Setting aside the importance of elevation (this is expected), we see the next two important features are distance to roadways and distance to fire points. We have reason to believe that distance to human activity is connected to the types of trees we find in the forest. This is yet another example of how our species shapes our environment. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top 4 Advantages and Disadvantages of Support Vector Machine or SVM](https://dhirajkumarblog.medium.com/top-4-advantages-and-disadvantages-of-support-vector-machine-or-svm-a3c06a2b107#:~:text=SVM%20algorithm%20is%20not%20suitable,samples%2C%20the%20SVM%20will%20underperform.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[K-Nearest Neighbors (KNN) Algorithm in Machine Learning](https://www.enjoyalgorithms.com/blog/k-nearest-neighbours-in-ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
