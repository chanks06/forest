{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5: Machine Learning Implementation & Evaluation \n",
    "## Predicting Forest Type \n",
    "\n",
    "### Final Project, Python for Data Science \n",
    "#### Willamette University MSDS \n",
    "by Charles Hanks, Carter McMahon, & Cleighton Roberts \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "The goal of our project was to predict the types of trees present in different areas of the Roosevelt National Forest in Colorado. We built a model using cartographic variables such as shadow coverage, distance to nearby landmarks, soil type, and local topography to classify tree type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The main problem we will address is how to identify the type of a tree based on its surroundings. If we know certain characteristics about a piece of land, such as elevation or the hillshade at noon, what sort of trees would we likely find there? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "\n",
    "* What cartographic feature is most predictive of tree type? \n",
    "* Which trees are most resilient to harsh geographic and climatic conditions? \n",
    "* Which trees need the least amount of sunlight? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "### Random Forest\n",
    "The final random forest model that we chose only differed from the default hyperparameters in that the number of estimators was set to 250 rather than 100. We decided to do that after testing higher values for min_sample_leaf, min_sample_split, and n_estimators using GridSearchCV. The results of that cross-validated hyperparameter tuning grid showed that the default values for min_sample_leaf and min_sample_split were best in our case, and that 250 was better than 100 for n_estimators. Due to our limited access to computing power, 250 was the highest value that we tested for n_estimators, so it is possible that an even higher value could have yielded better accuracy scores.\n",
    "\n",
    "### Support Vector Machine \n",
    "Given the computational expensive of training a SVM model on a dataset of this size, we utilized the RandomSearchCV tuning grid method to optimize the model. We focused on 2 hyperparameters: 'C', the misclassification penalty, and 'max_iter', the number of times the algorithm iterates. We chose a logarithmic range of values to try for 'C', and for each value, a random 'max_iter' value between 1000 and 5000. Each combination of these hyperparameters was passed through 3-fold cross validation in our grid search. From this randomized grid search, the best value for 'C' was 14.37, and the best value for 'max_iter' was 1902. Unfortunately, we saw negligible increase in model performance with the random search best parameters. \n",
    "\n",
    "### K Nearest Neighbors \n",
    "We wanted to try a KNN model for two reasons. First, KNN is a more simple and fast algorithm compared to RF and SVM. Second, we suspected that it would perform well on geospatial data given that it is based on distance between data points. The best value for hyperparamter K was 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Random Forest \n",
    "Despite our hyperparameter tuning efforts, the resulting improvement in accuracy over default settings was minimal. The tuned model produced an accuracy score of 0.952521 compared to 0.95201 with the default hyperparameter settings.\n",
    "\n",
    "### Support Vector Machine \n",
    "Our best SVM model was the basesline LinearSVC Model trained on 70% of the dataset. The accuracy score of this model was .72. \n",
    "\n",
    "### K-Nearest Neighbors \n",
    "Our KNN model's performance was a pleasant surprise. With a k = 5, The accuracy score was .92. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
